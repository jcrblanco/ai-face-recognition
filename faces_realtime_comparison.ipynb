{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604ec3df-59d0-4c35-9a36-9f453ab89f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "def faces_comparison_using_webcam():\n",
    "    # Inicializa la captura de video desde la webcam\n",
    "    video_capture = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "    # Verifica si la cámara pudo abrirse correctamente\n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Error: No se pudo abrir la cámara.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Lee el siguiente fotograma de la cámara\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Error: No se pudo leer un fotograma de la cámara.\")\n",
    "            break\n",
    "\n",
    "        # Convertir el fotograma de BGR (OpenCV) a RGB (face_recognition)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detecta ubicaciones de caras en el frame\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        # Obtener los encodings de las caras detectadas\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        # Dibujar un recuadro alrededor de cada cara detectada\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "            # Asegurarse de que las coordenadas estén dentro del frame\n",
    "            height, width = frame.shape[:2]\n",
    "            left, right, top, bottom = [max(0, min(val, dim)) for val, dim in zip((left, right, top, bottom), (width, width, height, height))]\n",
    "\n",
    "            # Dibujar el recuadro alrededor de la cara detectada\n",
    "            color = (0, 255, 0)  # Verde\n",
    "            thickness = 2  # Grosor del rectángulo\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, thickness)\n",
    "\n",
    "        # Comparar todas las caras detectadas entre sí\n",
    "        if len(face_encodings) >= 2:\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            for i in range(len(face_encodings)):\n",
    "                for j in range(i+1, len(face_encodings)):\n",
    "                    # Calcular la distancia de similitud entre las caras\n",
    "                    distance = face_recognition.face_distance([face_encodings[i]], face_encodings[j])[0]\n",
    "                    \n",
    "                    # Convertir la distancia en porcentaje de similitud\n",
    "                    similarity_percentage = (1 - distance) * 100\n",
    "                    print(f\"Similitud entre cara {i+1} y cara {j+1}: {similarity_percentage:.2f}%\")\n",
    "\n",
    "                    # Mostrar la similitud en el frame, en algún punto intermedio entre las dos caras\n",
    "                    top1, right1, bottom1, left1 = face_locations[i]\n",
    "                    top2, right2, bottom2, left2 = face_locations[j]\n",
    "                    \n",
    "                    # Calcular los puntos centrales de las dos caras\n",
    "                    center_x1, center_y1 = (left1 + right1) // 2, (top1 + bottom1) // 2\n",
    "                    center_x2, center_y2 = (left2 + right2) // 2, (top2 + bottom2) // 2\n",
    "                    \n",
    "                    # Dibujar una línea recta entre los puntos centrales de las dos caras\n",
    "                    line_color = (255, 0, 0)  # Azul\n",
    "                    line_thickness = 2\n",
    "                    cv2.line(frame, (center_x1, center_y1), (center_x2, center_y2), line_color, line_thickness)\n",
    "\n",
    "                    # Calcular el punto medio de la línea\n",
    "                    midpoint_x = (center_x1 + center_x2) // 2\n",
    "                    midpoint_y = (center_y1 + center_y2) // 2\n",
    "                    \n",
    "                    # Dibujar el porcentaje de similitud en la posición calculada\n",
    "                    cv2.putText(frame, f\"{similarity_percentage:.2f}%\", (midpoint_x, midpoint_y), font, 0.7, (255, 255, 255), 2)\n",
    "        else:\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, \"No se han detectado suficientes caras\", (50, 50), font, 1.0, (0, 0, 255), 2)\n",
    "\n",
    "        # Mostrar el frame procesado en tiempo real\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Salir con la tecla 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Liberar la cámara y cerrar ventanas\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Ejecutar el reconocimiento facial desde la webcam\n",
    "faces_comparison_using_webcam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab8b2eb-e52e-4b72-81ed-76b8d7d45237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628771b-af65-428f-b0bd-a6daf5c55ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
